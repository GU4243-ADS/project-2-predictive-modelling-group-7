---
title: "ms"
output: pdf_document
---

```{r setup, include=FALSE,warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("EBImage")
library("gtools")
cran <- getOption("repos")
cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
options(repos = cran)
install.packages("mxnet",dependencies = T)
library(mxnet)
library(caret)

```

```{r image cleanup, include=FALSE,warning = FALSE}

n <- 100
feat_n <- 28
files <- list.files(path="../data/train", pattern=".jpg",all.files=T, full.names=T, no.. = F)

labels <- read.csv("../data/train_label.txt",header = F)
files <- mixedsort(sort(files))
short_files <- files[1:n]
list_of_images <- lapply(short_files,readImage)
clean_img <- function(x)
{
  return (channel(resize(x,feat_n,feat_n),"gray"))
}

processed_images <- lapply(list_of_images, clean_img)
image_matrix <- t(do.call('cbind', lapply(processed_images,as.numeric)))
image_df <- as.data.frame(image_matrix)
image_df$label <- labels[1:n,1]     

#TRAINING

training_index <- createDataPartition(image_df$label, p = .9, times = 1)
training_index <- unlist(training_index)
train_set <- image_df[training_index,]
test_set <- image_df[-training_index,]

test_set$label

train_data <- data.matrix(train_set)
train_x <- t(train_data[, -ncol(train_data)])
train_y <- train_data[,ncol(train_data)]
train_array <- train_x
dim(train_array) <- c(feat_n, feat_n, 1, ncol(train_x))
test_data <- data.matrix(test_set)
test_x <- t(test_data[,-ncol(test_data)])
test_y <- test_data[,ncol(test_data)]
test_array <- test_x
dim(test_array) <- c(feat_n, feat_n, 1, ncol(test_x))

train_array

```

```{r}
## Model
mx_data <- mx.symbol.Variable('data')
## 1st convolutional layer 5x5 kernel and 20 filters.
conv_1 <- mx.symbol.Convolution(data = mx_data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2,2 ))
## 2nd convolutional layer 5x5 kernel and 50 filters.
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5,5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data = tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
## 1st fully connected layer
flat <- mx.symbol.Flatten(data = pool_2)
fcl_1 <- mx.symbol.FullyConnected(data = flat, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fcl_1, act_type = "tanh")
## 2nd fully connected layer
fcl_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 2)
## Output
NN_model <- mx.symbol.SoftmaxOutput(data = fcl_2)

## Set seed for reproducibility
mx.set.seed(10)

## Device used. Sadly not the GPU :-(
device <- mx.cpu()

## Train on 1200 samples
model <- mx.model.FeedForward.create(NN_model, X = train_array, y = train_y,
                                     ctx = device,
                                     num.round = 30,
                                     array.batch.size = 100,
                                     learning.rate = 0.05,
                                     momentum = 0.9,
                                     wd = 0.00001,
                                     eval.metric = mx.metric.accuracy,
                                     epoch.end.callback = mx.callback.log.train.metric(100))
```

```{r}

Image1 <- readImage("../data/train/pet1.jpg")
print(Image1)
as.numeric(Image1)
Image2 <- readImage("../data/train/pet2.jpg")
clean_img(Image1)
channel(Image1,"gray")
channel(Image2,"gray")

files
```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
