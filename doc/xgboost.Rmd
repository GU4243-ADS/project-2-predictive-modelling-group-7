---
title: "xgboost"
author: "Kenny Warner"
date: "March 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
```

```{r}

library(OpenImageR)
library(EBImage)

library(dplyr)
library(pbapply)

img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))

files <- mixedsort(sort(dir_names))

# test image 1
img0 <- readImage(paste0(img_dir,  files[1])) # change dir_names to files so images are in order pet1, pet2 instead of pet1, pet10. 

h1 <- HOG(img0, cells = 3, orientations = 6)

# store the HOG features
H <- matrix(NA, num_files,length(h1)) 

tm_feature_train <- system.time(for(i in 1:num_files){
  img <- readImage(paste0(img_dir, files[i]))
  H[i,] <- HOG(img,cells = 3, orientations = 6)
})

# output features
write.csv(H, file = "../output/hog_features.csv",row.names = F)

```

```{r}
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep = "")
img_test_dir <- paste(experiment_dir, "test/", sep = "")
```

```{r}

library(tidyverse)
label <- read_csv(paste('../data/train_label.txt', sep=''),
                   col_names = c('label'))

label <-ifelse(label$label == "dog", 1, 0) # binary classification, dog = 1, cat = 0. 

```

```{r}

library(xgboost)
hog <- read.csv("../output/hog_features.csv")

# sift <- read.csv("../pets/train-features")

hog$label <- label

# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(hog$label, SplitRatio = 0.8)
training_set = subset(hog, split == TRUE)
test_set = subset(hog, split == FALSE)

library(xgboost)
tm_train<- system.time(bst <- xgboost(data = as.matrix(training_set[-55]), 
               label = training_set$label,
               max.depth = 3,
               eta = .5,
               nround = 20,
               nthread = 2, objective = "binary:logistic"))

# Predicting the Test set results
tm_test <- system.time(y_pred <- predict(bst, newdata = as.matrix(test_set[-55])))
y_pred <- (y_pred >= 0.5)


```

###Validating results

```{r}

# Making the Confusion Matrix
cm = table(test_set[, 55], y_pred)

# Applying k-Fold Cross Validation
# install.packages('caret')
library(caret)
folds = createFolds(training_set$label, k = 10)
cv = lapply(folds, function(x) {
  training_fold = training_set[-x, ]
  test_fold = training_set[x, ]
  bst = xgboost(data = as.matrix(training_fold[-55]), 
               label = training_fold$label,
               max.depth = 4,
               eta = .5,
               nround = 20,
               nthread = 2, objective = "binary:logistic")
  y_pred = predict(bst, newdata = as.matrix(test_fold[-55]))
  y_pred = (y_pred >= 0.5)
  cm = table(test_fold[, 55], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))

```

###Summarize Running Time

```{r}

cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")

```
