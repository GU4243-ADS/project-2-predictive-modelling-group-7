---
title: "xgboost"
author: "Kenny Warner"
date: "March 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
```

###Confirm if testing or training

```{r}

#Select One
# test.set <- FALSE
test.set <- TRUE

```

##Extract Features

```{r}

library(OpenImageR)
library(EBImage)

library(dplyr)
library(pbapply)
library(gtools)


img_dir <- "../data/pets/train/" # change for test set
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))

files <- mixedsort(sort(dir_names))

# test image 1
img0 <- readImage(paste0(img_dir,  files[1])) # change dir_names to files so images are in order pet1, pet2 instead of pet1, pet10. 

h1 <- HOG(img0, cells = 3, orientations = 6)

# store the HOG features
H <- matrix(NA, num_files,length(h1)) 

tm_feature_train <- system.time(for(i in 1:num_files){
  img <- readImage(paste0(img_dir, files[i]))
  H[i,] <- HOG(img,cells = 3, orientations = 6)
})

# output features
write.csv(H, file = "../output/hog_features.csv",row.names = F)

```

#Label Data

```{r}

library(tidyverse)
label <- read_csv(paste('../data/train_label.txt', sep=''),
                   col_names = c('label'))

label <-ifelse(label$label == "dog", 1, 0) # binary classification, dog = 1, cat = 0. 

```

##Training and Testing Model

```{r}

library(xgboost)
hog <- read.csv("../output/hog_features.csv")

#Add Labels
hog$label <- label

# Splitting the dataset into the Training set and Test set to validate
# install.packages('caTools')

if (test.set == FALSE) {
  library(caTools)
  set.seed(123)

  split = sample.split(hog$label, SplitRatio = 0.8)
  training_set = subset(hog, split == TRUE)
  test_set = subset(hog, split == FALSE)

  library(xgboost)
  tm_train<- system.time(bst <- xgboost(data = as.matrix(training_set[-55]),
                 label = training_set$label,
                 max.depth = 3,
                 eta = .5,
                 nround = 20,
                 nthread = 2, objective = "binary:logistic"))

  # Predicting the Test set results
  tm_test <- system.time(y_pred <- predict(bst, newdata = as.matrix(test_set[-55])))
  y_pred <- (y_pred >= 0.5) }

```

```{r}

###Training on all the data to save the final model
if (test.set == FALSE) {
  library(xgboost)
  tm_train<- system.time(bst <- xgboost(data = as.matrix(hog[-55]),
                 label = hog$label,
                 max.depth = 3,
                 eta = .5,
                 nround = 20,
                 nthread = 2, objective = "binary:logistic"))
  
  # Predicting the Test set results
  tm_test <- system.time(y_pred <- predict(bst, newdata = as.matrix(test_set[-55])))
  y_pred <- (y_pred >= 0.5)

saveRDS(bst, "./xgboost_model.rds")}
  

```

```{r}
####Testing only on test set 

if (test.set == TRUE) {
  bst <- readRDS("./xgboost_model.rds")
  test_set <- hog
  test_set$label <- label
  
  # Predicting the Test set results
  tm_test <- system.time(y_pred <- predict(bst, newdata = as.matrix(test_set[-55])))
  y_pred <- (y_pred >= 0.5) 
  cm = table(test_set[, 55], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])}


```

###Validating results - Skip if testing

```{r}

if (test.set == FALSE) {
  # Making the Confusion Matrix
  cm = table(test_set[, 55], y_pred)
  
  # Applying k-Fold Cross Validation
  # install.packages('caret')
  library(caret)
  folds = createFolds(training_set$label, k = 10)
  cv = lapply(folds, function(x) {
    training_fold = training_set[-x, ]
    test_fold = training_set[x, ]
    bst = xgboost(data = as.matrix(training_fold[-55]), 
                 label = training_fold$label,
                 max.depth = 3,
                 eta = .5,
                 nround = 20,
                 nthread = 2, objective = "binary:logistic")
    y_pred = predict(bst, newdata = as.matrix(test_fold[-55]))
    y_pred = (y_pred >= 0.5)
    cm = table(test_fold[, 55], y_pred)
    accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
    return(accuracy)
  })
  accuracy = mean(as.numeric(cv)) }

```

###Summarize Running Time

```{r}

cat("Time for constructing training features=", tm_feature_train[1], "s \n")

if (test.set == FALSE) {
  cat("Time for training model=", tm_train[1], "s \n") }

cat("Time for making prediction=", tm_test[1], "s \n")

```
