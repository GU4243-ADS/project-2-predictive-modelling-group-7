img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))
# test image 1
# img0 <- readImage(paste0(img_dir,  dir_names[1]))
# h1 <- HOG(img0,cells = 8,orientations = 9)
# store the HOG features
# H <- matrix(NA, num_files,length(h1))
for(i in 1:num_files){
img <- readImage(paste0(img_dir, dir_names[i]))
H[i,] <- HOG(img,cells = 8,orientations = 9)
}
# output features
write.csv(H, file = "../output/hog_features.csv",row.names = F)
num_files
# store the HOG features
H <- matrix(NA, num_files,length(num_files))
library(OpenImageR)
library(EBImage)
library("dplyr")
img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))
# test image 1
# img0 <- readImage(paste0(img_dir,  dir_names[1]))
# h1 <- HOG(img0,cells = 8,orientations = 9)
# store the HOG features
H <- matrix(NA, num_files,length(num_files))
for(i in 1:num_files){
img <- readImage(paste0(img_dir, dir_names[i]))
H[i,] <- HOG(img,cells = 8,orientations = 9)
}
library(OpenImageR)
library(EBImage)
library("dplyr")
img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))
# test image 1
img0 <- readImage(paste0(img_dir,  dir_names[1]))
h1 <- HOG(img0,cells = 8,orientations = 9)
# store the HOG features
H <- matrix(NA, num_files,length(h1))
for(i in 1:num_files){
img <- readImage(paste0(img_dir, dir_names[i]))
H[i,] <- HOG(img,cells = 8,orientations = 9)
}
# output features
write.csv(H, file = "../output/hog_features.csv",row.names = F)
knitr::opts_chunk$set(echo = TRUE)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep = "")
img_test_dir <- paste(experiment_dir, "test/", sep = "")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
seed              <- TRUE # set seed for random subset of train and test
train.proportion  <- 0.75
library(tidyverse)
label <- read_csv(paste('../data/train_label.txt', sep=''),
col_names = c('label'))
label <-ifelse(label$label == "dog", 1, 0) # binary classification, dog = 1, cat = 0.
n <- length(label)
if(seed) {
set.seed(2184)
random.split <- sample(n, round(train.proportion*n, 1), replace = F)
} else {
random.split <- sample(n, round(train.proportion*n, 1), replace = F)
}
# label_small <- as.numeric(label_train[1:200])
hog <- read.csv("../output/hog_features.csv")
hog_train <- hog[random.split, ]
label_train <- label[random.split]
train_matrix <- xgb.DMatrix(data = as.matrix(hog_train), label = label_train)
library(xgboost)
hog <- read.csv("../output/hog_features.csv")
hog_train <- hog[random.split, ]
label_train <- label[random.split]
train_matrix <- xgb.DMatrix(data = as.matrix(hog_train), label = label_train)
hog_test <- hog[-random.split, ]
label_test <- label[-random.split]
text_matrix <- xgb.DMatrix(data = as.matrix(hog_test), label = label_test)
library(xgboost)
bst = xgboost(data = train_matrix, label = label_train,
max.depth = 3,
eta = .5,
nround = 10,
nthread = 2, objective = "binary:logistic")
library(dplyr)
pred = predict(bst, train_matrix)
prediction <- matrix(pred, nrow = 3, ncol = length(pred)/3) %>%
t() %>%
data.frame() %>%
mutate(label =label_test + 1, max_prob = max.col(., "last"))
# test.error <- sum(predict(bst, data.matrix(test[,-1])) != test[-1]/length(test[,1]))
pred
View(prediction)
for (h in seq(1, 10, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(10, 100, 10)){
tune <- xgboost(data = train_matrix, label = label_train,
max.depth = k,
eta = i,
nround = j,
nthread = 2, objective = "binary:logistic")
}
library(xgboost)
hog <- read.csv("../output/hog_features.csv")
hog_train <- hog[random.split, ]
label_train <- label[random.split]
train_matrix <- xgb.DMatrix(data = as.matrix(hog_train), label = label_train)
hog_test <- hog[-random.split, ]
label_test <- label[-random.split]
text_matrix <- xgb.DMatrix(data = as.matrix(hog_test), label = label_test)
for (h in seq(1, 10, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(10, 100, 10)){
tune <- xgboost(data = train_matrix, label = label_train,
max.depth = h,
eta = i,
nround = j,
nthread = 2, objective = "binary:logistic")
}
model_values = list()
k = 1
for (h in seq(1, 10, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(10, 100, 10)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
model_values
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(10, 100, 10)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
View(model_values)
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
View(model_values)
if(run.cv){
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
err_cv <- array(dim = c(length(model_values), 3))
for(k in length(model_values)){
cat("k =", k, "\n")
err_cv[ ,k] <- cv.function(dat_train, label_train, model_values[[k]], model, K)
}
save(err_cv, file = paste0("../output.err_cv_", model, ".RData"))
}
if(run.cv){
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
err_cv <- array(dim = c(length(model_values), 3))
for(k in length(model_values)){
cat("k =", k, "\n")
err_cv[ ,k] <- xgb.cv(dat_train, label_train, model_values[[k]], model, K)
}
save(err_cv, file = paste0("../output.err_cv_", model, ".RData"))
}
library(xgboost)
hog <- read.csv("../output/hog_features.csv")
hog_train <- hog[random.split, ]
label_train <- label[random.split]
dat_train <- xgb.DMatrix(data = as.matrix(hog_train), label = label_train)
hog_test <- hog[-random.split, ]
label_test <- label[-random.split]
text_matrix <- xgb.DMatrix(data = as.matrix(hog_test), label = label_test)
library(xgboost)
bst = xgboost(data = dat_train, label = label_train,
max.depth = 3,
eta = .5,
nround = 10,
nthread = 2, objective = "binary:logistic")
library(dplyr)
pred = predict(bst, dat_train)
prediction <- matrix(pred, nrow = 3, ncol = length(pred)/3) %>%
t() %>%
data.frame() %>%
mutate(label = label_test + 1, max_prob = max.col(., "last"))
# test.error <- sum(predict(bst, data.matrix(test[,-1])) != test[-1]/length(test[,1]))
model = xgboost()
model = xgboost
if(run.cv){
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
err_cv <- array(dim = c(length(model_values), 3))
for(k in length(model_values)){
cat("k =", k, "\n")
err_cv[ ,k] <- xgb.cv(dat_train, label_train, model_values[[k]], model, K)
}
save(err_cv, file = paste0("../output.err_cv_", model, ".RData"))
}
if(run.cv){
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
err_cv <- array(dim = c(length(model_values), 3))
for(k in length(model_values)){
cat("k =", k, "\n")
err_cv[ ,k] <- xgb.cv(dat_train, label_train, model_values[[k]], model, K)
}
save(err_cv, file = paste0("../output.err_cv_", model, ".RData"))
}
model = xgboost
if(run.cv){
model_values = list()
k = 1
for (h in seq(1, 5, 1)){
for (i in seq(0, 1, .1)) {
for (j in seq(0, 100, 25)){
model_values[[k]] = list(max.depth = h, eta = i, nround = j)
k = k + 1
}
err_cv <- array(dim = c(length(model_values), 3))
for(k in length(model_values)){
cat("k =", k, "\n")
err_cv[ ,k] <- xgb.cv(dat_train, label_train, model_values[[k]], K)
}
save(err_cv, file = paste0("../output.err_cv_", model, ".RData"))
}
rm(list = ls())
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
setwd("Spring2018/Project_Starter_Codes/Project2-PredictiveModelling/doc")
setwd("/Users/Nicole/Documents/GitHub/project-2-predictive-modelling-group-7/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- read.table(paste(experiment_dir, "/Users/Nicole/Documents/GitHub/project-2-predictive-modelling-group-7/data/train_label.txt", sep = ""), header = F)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
source("../lib/feature.R")
setwd("/Users/Nicole/Documents/GitHub/project-2-predictive-modelling-group-7/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
source("../lib/feature.R")
experiment_dir <- "..data/" # This will be modified for different data sets.
setwd("/Users/Nicole/Documents/GitHub/project-2-predictive-modelling-group-7/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "..data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
getwd()
experiment_dir <- "..data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "9")
label_train <- ifelse(label_train$label == "dog", 1, 0)
View(label_train)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
View(label_train)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- ifelse(label_train$label == "dog", 1, 0)
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train",
data_name = "pets", export = TRUE))
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train",
export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train",
export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train",
export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_test <- NA
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train"))
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train"))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = T))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
source("../lib/rowmeans.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", export = TRUE))
}
knitr::opts_chunk$set(echo = TRUE)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
library(OpenImageR)
library(EBImage)
library(dplyr)
library(pbapply)
img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))
files <- mixedsort(sort(dir_names))
library(gtools)
knitr::opts_chunk$set(echo = TRUE)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
library(OpenImageR)
library(EBImage)
library(dplyr)
library(pbapply)
img_dir <- "../data/train/"
dir_names <- list.files(img_dir)
num_files <- length(list.files(img_dir))
files <- mixedsort(sort(dir_names))
# test image 1
img0 <- readImage(paste0(img_dir,  files[1])) # change dir_names to files so images are in order pet1, pet2 instead of pet1, pet10.
h1 <- HOG(img0, cells = 3, orientations = 6)
# store the HOG features
H <- matrix(NA, num_files,length(h1))
tm_feature_train <- system.time(for(i in 1:num_files){
img <- readImage(paste0(img_dir, files[i]))
H[i,] <- HOG(img,cells = 3, orientations = 6)
})
# output features
write.csv(H, file = "../output/hog_features.csv",row.names = F)
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep = "")
img_test_dir <- paste(experiment_dir, "test/", sep = "")
library(tidyverse)
label <- read_csv(paste('../data/train_label.txt', sep=''),
col_names = c('label'))
label <-ifelse(label$label == "dog", 1, 0) # binary classification, dog = 1, cat = 0.
library(xgboost)
hog <- read.csv("../output/hog_features.csv")
# sift <- read.csv("../pets/train-features")
hog$label <- label
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(hog$label, SplitRatio = 0.8)
training_set = subset(hog, split == TRUE)
test_set = subset(hog, split == FALSE)
library(xgboost)
tm_train<- system.time(bst <- xgboost(data = as.matrix(training_set[-55]),
label = training_set$label,
max.depth = 3,
eta = .5,
nround = 20,
nthread = 2, objective = "binary:logistic"))
# Predicting the Test set results
tm_test <- system.time(y_pred <- predict(bst, newdata = as.matrix(test_set[-55])))
y_pred <- (y_pred >= 0.5)
# Making the Confusion Matrix
cm = table(test_set[, 55], y_pred)
# Applying k-Fold Cross Validation
# install.packages('caret')
library(caret)
folds = createFolds(training_set$label, k = 10)
cv = lapply(folds, function(x) {
training_fold = training_set[-x, ]
test_fold = training_set[x, ]
bst = xgboost(data = as.matrix(training_fold[-55]),
label = training_fold$label,
max.depth = 4,
eta = .5,
nround = 20,
nthread = 2, objective = "binary:logistic")
y_pred = predict(bst, newdata = as.matrix(test_fold[-55]))
y_pred = (y_pred >= 0.5)
cm = table(test_fold[, 55], y_pred)
accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
return(accuracy)
})
accuracy = mean(as.numeric(cv))
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
